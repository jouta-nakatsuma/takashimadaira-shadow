from openai import OpenAI
import subprocess
import os
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def run_logs():
    print("ğŸ“¦ docker compose logs app ã‚’å–å¾—ä¸­...")
    result = subprocess.run(["docker", "compose", "logs", "app"], capture_output=True, text=True, check=True)
    return result.stdout[-2000:]  # æœ€æ–°ãƒ­ã‚°ã‚’å–å¾—

def ask_agent(logs: str):
    messages = [
        {
            "role": "system",
            "content": "ã‚ãªãŸã¯Flask + Docker + Pythonã®ç†Ÿç·´ãƒ‡ãƒãƒƒã‚°AIã§ã™ã€‚å®‰å…¨ãƒ»ç¢ºå®Ÿãªæ‰‹é †ã‚’å¤§äº‹ã«ã—ã¦ãã ã•ã„ã€‚"
        },
        {
            "role": "user",
            "content": f"""
ä»¥ä¸‹ã¯Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆAIã‚¦ã‚°ã‚¤ã‚¹ï¼‰ã®ãƒ­ã‚°ã§ã™ã€‚
èµ·å‹•æ™‚ã«å•é¡ŒãŒã‚ã‚Šãã†ã§ã™ã€‚åŸå› ã¨æ¨å¥¨ã•ã‚Œã‚‹ç¢ºèªãƒ»ä¿®æ­£æ‰‹é †ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
{logs}
"""
        }
    ]
    print("ğŸ¤– GPTã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«è³ªå•ã—ã¦ã„ã¾ã™...")
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.2,
    )
    return response.choices[0].message.content

def main():
    logs = run_logs()
    answer = ask_agent(logs)
    print("\n--- ğŸ§  GPTã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ææ¡ˆ ---\n")
    print(answer)

if __name__ == "__main__":
    main()
